def slackChannel = '#ego-svc-jenkins-ags'

def msg = "${buildStatus}${icons}: `${env.JOB_NAME}`\n ${env.BUILD_DISPLAY_NAME}:\nSOURCE=${env.SOURCE}\n<${env.BUILD_URL}console|Watch build console output> @here"

common = load "../lib/common.groovy"

def autoCancelled = false
def label = "game-server-scale-up-${UUID.randomUUID().toString()}"

podTemplate(name: 'game-server-scale-up-for-operation', label: label, yaml: """
kind: Pod
metadata:
  name: microservice-orchestration
spec:
  containers:
  - name: microservice-orchestration
    image: 407733091588.dkr.ecr.us-west-2.amazonaws.com/ego-cicd/microservice-orchestration:1.0.14
    imagePullPolicy: Always
    command:
    - /bin/cat
    tty: true
    env:
    - name: STACK_NAME
      value: "env-prod-1"
    - name: CLUSTER_NAME
      value: "prod-1"
"""
  ) {
node(label) {
  try {
    def secrets = [[$class: 'VaultSecret', path: 'cicd/prod-1/aws_keys', secretValues: [
                    [$class: 'VaultSecretValue', envVar: 'AWS_ACCESS_KEY_ID', vaultKey: 'AWS_ACCESS_KEY_ID'],
                    [$class: 'VaultSecretValue', envVar: 'AWS_SECRET_ACCESS_KEY', vaultKey: 'AWS_SECRET_ACCESS_KEY']]],
                  [$class: 'VaultSecret', path: 'cicd/bitbucket', secretValues: [
                    [$class: 'VaultSecretValue', envVar: 'BITBUCKET_USER', vaultKey: 'BITBUCKET_USER'],
                    [$class: 'VaultSecretValue', envVar: 'BITBUCKET_APP_PASSWORD', vaultKey: 'BITBUCKET_APP_PASSWORD']]],
                  [$class: 'VaultSecret', path: 'cicd/artifactory', secretValues: [
                    [$class: 'VaultSecretValue', envVar: 'ART_BUILD_USER', vaultKey: 'ART_BUILD_USER'],
                    [$class: 'VaultSecretValue', envVar: 'ART_BUILD_PASSWORD', vaultKey: 'ART_BUILD_PASSWORD']]]]

    withCredentials([string(credentialsId: 'EGO_VAULT_ROLE_ID', variable: 'EGO_VAULT_ROLE_ID'), string(credentialsId: 'EGO_VAULT_SECRET_ID', variable: 'EGO_VAULT_SECRET_ID')]) {
    echo "${EGO_VAULT_ROLE_ID}"

        wrap([$class: 'VaultBuildWrapper', vaultSecrets: secrets]) {
  properties([
          parameters([choice(choices: ['game-server', 'game-server2'], description: 'The game-server tier', name: 'AGS_TIER_ID'),
                      string(defaultValue: 'withme', description: 'The publisher organization id', name: 'ORG_ID', trim: true),
                      string(defaultValue: '30', description: 'The number of AWS EC2 Instances required for full operation', name: 'INSTANCES', trim: true),
                      string(defaultValue: '120', description: 'The number of AGS Pods required for for full operation', name: 'REPLICAS', trim: true),
                      string(defaultValue: '', description: 'The source of this build', name: 'SOURCE', trim: true)]),
          disableConcurrentBuilds()
      ])
    env.AGS_TIER_ID = "${params.AGS_TIER_ID}"
    env.VAULT_APP_ID = "authoritative-game-server-${params.ORG_ID}"
    env.HELM_VALUES_FILE = "authoritative-${env.AGS_TIER_ID}-${params.ORG_ID}-values.yaml"
    env.SCEPTRE_VALUES_FILE = "nodes.yaml"
    if (env.AGS_TIER_ID == 'game-server2') {
      env.SCEPTRE_VALUES_FILE = "nodes2.yaml"
    }
    env.APP_NAME = "authoritative-${env.AGS_TIER_ID}-${params.ORG_ID}"
    env.POD_NAME = "${env.AGS_TIER_ID}-${params.ORG_ID}"
    env.JOB_NAME = "${env.JOB_NAME}"
    env.BUILD_NUMBER = "${env.BUILD_NUMBER}"
    env.INSTANCES = "${params.INSTANCES}"
    env.REPLICAS = "${params.REPLICAS}"
    env.SOURCE = "${params.SOURCE}"
    currentBuild.displayName = "#${env.BUILD_NUMBER} `${env.APP_NAME}`"
    env.GIT_BRANCH = "master"

    stage('Validate input arguments') {
      container('microservice-orchestration')  {
      sh '''#!/usr/bin/env bash
        set -eo pipefail
        if [[ ! ${INSTANCES} =~ ^[0-9]+$ ]]; then
          echo "Invalid Jenkins input for INSTANCES: [${INSTANCES}].  It must be a positive integer."
          exit 1
        fi
        if [[ "${INSTANCES}" -lt 3 ]]; then
          echo "Invalid Jenkins input for INSTANCES: [${INSTANCES}].  It must be at least 3."
          exit 1
        fi
        if [[ ! ${REPLICAS} =~ ^[0-9]+$ ]]; then
          echo "Invalid Jenkins input for REPLICAS: [${REPLICAS}].  It must be a positive integer."
          exit 1
        fi
        if [[ "${REPLICAS}" -lt 3 ]]; then
          echo "Invalid Jenkins input for REPLICAS: [${REPLICAS}].  It must be at least 3."
          exit 1
        fi
      '''
    }}
    stage('Configure aws account and kubectl config') {
      container('microservice-orchestration')  {
      sh '''#!/usr/bin/env bash
        set -eox pipefail
        /toolbox/set-aws-credentials.sh --key-id ${AWS_ACCESS_KEY_ID} --secret-access-key ${AWS_SECRET_ACCESS_KEY}
        /toolbox/add-aws-profile-credentials.sh --profile-name prod --key-id ${AWS_ACCESS_KEY_ID} --secret-access-key ${AWS_SECRET_ACCESS_KEY}
        ### Check IAM user
        aws sts get-caller-identity --output text
        ### Configure kubectl
        aws eks --region us-west-2 update-kubeconfig --name ${CLUSTER_NAME}
        ### Check kubectl context
        kubectl config current-context
      '''
    }}
    stage('Validate AGS state') {
      container('microservice-orchestration')  {
      sh '''#!/usr/bin/env bash
        set -eo pipefail
        source /toolbox/automation-scripts/autoscaling-group-functions.sh
        ### Make sure the AWS EC2 Autoscaling Group has fewer instances that what is requested
        getAwsAutoscalingGroup "_autoscaling_group" ${CLUSTER_NAME} "${AGS_TIER_ID}-tier"
        if [[ "${_autoscaling_group}" != *"game-server"* ]]; then
          echo "Autoscaling group: ${_autoscaling_group}"
          echo "No AWS EC2 Autoscaling Group found for cluster [${CLUSTER_NAME}] and node group [${AGS_TIER_ID}-tier]."
          exit 1
        fi
        getAwsAutoscalingGroupCurrentSize "_autoscaling_group_size" ${_autoscaling_group}
        if [[ "${INSTANCES}" -lt "${_autoscaling_group_size}" ]]; then
          echo "Invalid Jenkins input for INSTANCES: [${INSTANCES}].  It must be at least the number of running instances: ${_autoscaling_group_size}."
          exit 1
        fi
        echo "Autoscaling Group [${_autoscaling_group}] is running with ${_autoscaling_group_size} instances."

        ### Make sure the Kubernetes Statefulset has fewer instances that what is requested but at least one
        replicas=$(kubectl -n default get statefulset ${POD_NAME} -o jsonpath='{.status.readyReplicas}')
        if [[ -z "${replicas}" ]]; then
          echo "There are no ready replicas for ${POD_NAME}.  Run the game-server-prep-for-review pipeline."
          exit 1
        fi
        echo "Statefulset ${POD_NAME} is running with ${replicas} ready replicas."
        if [[ "${REPLICAS}" -lt "${replicas}" ]]; then
          echo "Invalid Jenkins input for REPLICAS: [${REPLICAS}].  It must be at least the number of running replicas: ${replicas}."
          exit 1
        fi
      '''
    }}
    stage('Scale up game-server') {
      container('microservice-orchestration')  {
      sh '''#!/usr/bin/env bash
        set -eo pipefail
        ### Use this function to try and restore the autoscaling group to its base state
        function rollbackAutoscalingGroupOnFailure() {
          local _rollbackAutoscalingGroup=$1
          local _sceptreValuesFile=$2
          if [[ ${_rollbackAutoscalingGroup} ]]; then
            echo "***"
            echo "*** ROLLBACK: Return the Autoscaling Group to its base state"
            echo "***"
            git checkout -- ${_sceptreValuesFile}
            pushd aws > /dev/null 2>&1
            sceptre update us-west-2/game-server-tier/${SCEPTRE_VALUES_FILE} --yes || true
            popd > /dev/null 2>&1
            echo "Done attempting to return the ${AGS_TIER_ID} to its base state"
            assertAwsAutoscalingGroupInBaseState ${_autoscaling_group}
            exit 1
          fi
        }
        function waitForDesiredReadyNodes() {
          local _result_var=$1
          local _counter=0
          local _result="success"
          echo "Check to see if ${INSTANCES} Kubernetes Nodes are ready."
          local _nodeCount=$(kubectl -n default get nodes -l prod-1-tier=${AGS_TIER_ID} | grep Ready | wc -l)
          until [ "${INSTANCES}" == "${_nodeCount}" ]; do
            if [[ "${_counter}" -lt 120 ]]; then
              _counter=$(( _counter + 1))
              sleep 5
              _nodeCount=$(kubectl -n default get nodes -l prod-1-tier=${AGS_TIER_ID} | grep Ready | wc -l)
              if [[ -z "${_nodeCount}" ]]; then
                _nodeCount="0"
              fi
              echo "${_counter}. Ready Nodes: ${_nodeCount}.  Waiting for a total of ${INSTANCES}..."
            else
              # Break out of the loop with result set to failure
              echo "Expected ${INSTANCES} but only ${_nodeCount} were ready after ten minutes."
              _nodeCount=${INSTANCES}
              _result="failure"
            fi
          done
          echo "Result from waiting for ready nodes: ${_result}"
          eval $_result_var="'${_result}'"
        }
        ### Clone repo environment repository
        git clone https://${BITBUCKET_USER}:${BITBUCKET_APP_PASSWORD}@bitbucket.org/imvu/${STACK_NAME}.git && cd ${STACK_NAME}
        git fetch && git checkout ${GIT_BRANCH}
        ### Pull EGO Helm charts from Artifactory Helm repo
        helm repo add ego-helm-release https://withme.jfrog.io/withme/ego-helm-release/ --username $ART_BUILD_USER --password $ART_BUILD_PASSWORD && helm repo update

        ### Scale up the AWS Autoscaling Group to the operational state
        source /toolbox/automation-scripts/autoscaling-group-functions.sh
        sceptreValuesFile="aws/config/us-west-2/game-server-tier/${SCEPTRE_VALUES_FILE}"
        echo "Edit ${sceptreValuesFile} to set NodeAutoScalingGroupDesiredCapacity to ${INSTANCES}:"
        sed -i "s/NodeAutoScalingGroupDesiredCapacity: .*/NodeAutoScalingGroupDesiredCapacity: '${INSTANCES}'/g" ${sceptreValuesFile}
        git diff ${sceptreValuesFile}
        pushd aws > /dev/null 2>&1
        ### This command always returns a non-zero exit code even when it succeeds (see ES-1328)
        sceptre update us-west-2/game-server-tier/${SCEPTRE_VALUES_FILE} --yes || true
        popd > /dev/null 2>&1
        rollbackAutoscalingGroup=false

        ### Verify the AWS Autoscaling Group is in the operational state
        getAwsAutoscalingGroup "_autoscaling_group" ${CLUSTER_NAME} "${AGS_TIER_ID}-tier"
        if [[ "${_autoscaling_group}" != *"game-server"* ]]; then
          echo "Autoscaling group: ${_autoscaling_group}"
          echo "No AWS EC2 Autoscaling Group found for cluster [${CLUSTER_NAME}] and node group [${AGS_TIER_ID}-tier]."
          exit 1
        fi
        getAwsAutoscalingGroupCurrentSize "_autoscaling_group_size" ${_autoscaling_group}
        if [[ "${_autoscaling_group_size}" != "${INSTANCES}" ]]; then
          echo "Expected ${_autoscaling_group} to have ${INSTANCES} instances but found instead ${_autoscaling_group_size}"
          rollbackAutoscalingGroupOnFailure true ${sceptreValuesFile}
        fi
        echo "Autoscaling Group [${_autoscaling_group}] is in its minimal state for review"

        ### Verify the AWS EC2 Instances are available as Kubernetes Nodes
        waitForDesiredReadyNodes "_nodesReadyResult"
        if [[ "${_nodesReadyResult}" != "success" ]]; then
          echo "Kubernetes Nodes are not all ready."
          rollbackAutoscalingGroupOnFailure true ${sceptreValuesFile}
        fi
        echo "All ${INSTANCES} Kubernetes Nodes are ready."

        ### Fetch credentials from Vault
        echo "Get credentials from Vault"
        vault_token=$(vault write -address="https://vault.withme.com/" -format=json auth/approle/login role_id=${EGO_VAULT_ROLE_ID} secret_id=${EGO_VAULT_SECRET_ID} | jq .auth.client_token | sed -e 's/^"//' -e 's/"$//') || rollbackAutoscalingGroup=true
        vault login -address="https://vault.withme.com/" token=${vault_token} > /dev/null 2>&1  || rollbackAutoscalingGroup=true
        fetchedSecrets=$(vault kv get -address="https://vault.withme.com/" -format=json cicd/${CLUSTER_NAME}/base64/${VAULT_APP_ID} | jq -r '.data | to_entries | .[] | .key + "=" + .value' | sed "s/^/--set-string secret.secretContents./g" | xargs)  || rollbackAutoscalingGroup=true
        if [[ ${_rollbackAutoscalingGroup} ]]; then
          echo "Unable to get credentials from Vault"
          rollbackAutoscalingGroupOnFailure true ${sceptreValuesFile}
        fi

        ### Edit the number of replicas in the AGS helm "values.yaml" file
        values_file="k8s/game-server-tier/${HELM_VALUES_FILE}"
        echo "Edit ${values_file} to set the replicas to ${REPLICAS}:"
        sed -i 's/replicas: .*/replicas: '${REPLICAS}'/g' ${values_file}
        git --no-pager diff ${values_file}

        ### Scale up the AGS pods to the minimal level required for review
        echo "Scale up the game servers to ${REPLICAS} replicas."
        helm upgrade ${POD_NAME} ego-helm-release/authoritative-game-server -f ${values_file} --namespace=default --reuse-values --atomic --wait --timeout 1800s --install ${fetchedSecrets} || true
        replicas=$(kubectl -n default get statefulset ${POD_NAME} -o jsonpath='{.status.readyReplicas}')
        echo "Ready replicas: ${replicas}"
        if [[ "${replicas}" != "${REPLICAS}" ]]; then
          echo "Expected ${REPLICAS} ready replicas for ${POD_NAME}."
          echo "Rollback helm upgrades with best effort"
          helm rollback "${POD_NAME}" --namespace=default || true
          rollbackAutoscalingGroupOnFailure true ${sceptreValuesFile}
        fi
        echo "successfully scaled up the ${POD_NAME} Pod count to ${REPLICAS}"
        echo "Statefulset ${POD_NAME} is in its minimal state with ${replicas} game servers ready for QA."
      '''
    }}
    stage('Push deployed version to env-prod-1') {
      container('microservice-orchestration')  {
      sh '''#!/usr/bin/env bash
        set -eo pipefail
        cd ${STACK_NAME} && git checkout ${GIT_BRANCH}
        git config --global user.name "jenkins"
        git config --global user.email "jenkins@imvu.com"
        git diff-index --quiet HEAD || git commit -am "Scale up ${APP_NAME} for operation. ${JOB_NAME}:#${BUILD_NUMBER}"
        # Added loop in case if developers push changes to "env-prod-1" repo while AGS pipeline running.
        COUNTER=0
        until git push origin ${GIT_BRANCH}
        do
          if [[ "${COUNTER}" -eq '120' ]]; then
            echo "Can't push to ${GIT_BRANCH} branch. Something wrong with Bitbucket or with repository"
            exit 1
          else
            sleep 1s
            COUNTER=$(( COUNTER + 1))
            echo "Pull and try again"
            git pull
          fi
        done
      '''
    }}}
    }} catch (e) {
      if ( autoCancelled ) {
        currentBuild.result = 'ABORTED'
        throw e
      } else {
        currentBuild.result = 'FAILURE'
        throw e
      }
    } finally {
      stage('Send notifications') {
        container('microservice-orchestration')  {
        if (currentBuild.result == 'ABORTED') {
            common.notifySlack(currentBuild.result, slackChannel, "", msg)
            common.notifySlack(currentBuild.result, slackChannel, '#FFFE89', "`${env.JOB_NAME}`\n ${env.BUILD_DISPLAY_NAME}: \n'AGS version not valid or empty. Pipeline aborted!'")
        }
        if (currentBuild.result == 'FAILURE') {
            common.notifySlack(currentBuild.result, slackChannel)
        }
        if (currentBuild.result != 'FAILURE' && currentBuild.result != 'ABORTED') {
            common.notifySlack(currentBuild.result, slackChannel)
        }}}}
}}
